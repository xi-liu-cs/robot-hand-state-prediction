{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hoo8TXchJyV",
    "outputId": "8c7eb201-6d07-492e-be7e-4858316c8c42",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount = True)\n",
    "# %cd /content/gdrive/MyDrive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgxBKoKihaQK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E81RvS6HhJyW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T2drsQbphJyX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_tr = '.\\\\lazydata\\\\'\n",
    "path_te = '.\\\\lazydata\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SxLxI9g_hJyX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class load(Dataset):\n",
    "    def __init__(self, path, isTrain=True, transform = None):\n",
    "        self.transform = transform\n",
    "        path = path + ('train\\\\' if isTrain else 'test\\\\')\n",
    "        self.pathx = path + 'X\\\\'\n",
    "        self.pathy = path + 'Y\\\\'\n",
    "        self.data = os.listdir(self.pathx)\n",
    "        self.isTrain = isTrain\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.data[idx]\n",
    "        img0 = cv2.imread(self.pathx + f + '\\\\rgb\\\\0.png')\n",
    "        img1 = cv2.imread(self.pathx + f + '\\\\rgb\\\\1.png')\n",
    "        img2 = cv2.imread(self.pathx + f + '\\\\rgb\\\\2.png')\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        depth = np.load(self.pathx + f + '\\\\depth.npy')\n",
    "        field_id = pkl.load(open(self.pathx + f + '\\\\field_id.pkl', 'rb'))\n",
    "        if self.isTrain == False:\n",
    "            return (img0, img1, img2, depth, torch.tensor(int(field_id)))\n",
    "        y = np.load(self.pathy + f + '.npy')\n",
    "        return (img0, img1, img2, depth, torch.tensor(int(field_id))), torch.tensor(y)\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rLcyfu9NhJyX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_train = load(path_tr, isTrain = True)\n",
    "data_test = load(path_te, isTrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tensorToArray(data, isTrain=True):\n",
    "    n_samples = len(data)\n",
    "    if isTrain:\n",
    "        (img0_, img1_, img2_, depth_, field_id_), y_ = data[0]\n",
    "        img_shape, depth_shape, n_y = img0_.shape, depth_.shape, len(y_)\n",
    "        y_array = np.empty(shape=(n_samples, n_y))\n",
    "    else:\n",
    "        (img0_, img1_, img2_, depth_, field_id_)= data[0]\n",
    "        img_shape, depth_shape = img0_.shape, depth_.shape\n",
    "    img0_array = np.empty(shape=(n_samples, img_shape[0], img_shape[1], img_shape[2]))\n",
    "    img1_array = np.empty(shape=(n_samples, img_shape[0], img_shape[1], img_shape[2]))\n",
    "    img2_array = np.empty(shape=(n_samples, img_shape[0], img_shape[1], img_shape[2]))\n",
    "    depth_array = np.empty(shape=(n_samples, depth_shape[0], depth_shape[1], depth_shape[2]))\n",
    "\n",
    "    for inx, d in enumerate(data):\n",
    "        # print(inx)\n",
    "        if isTrain:\n",
    "            (img0, img1, img2, depth, field_id), y = d\n",
    "            y_array[inx, :] = np.array(y)\n",
    "            img0_array[inx, :, :, :] = img0\n",
    "            img1_array[inx, :, :, :] = img1\n",
    "            img2_array[inx, :, :, :] = img2\n",
    "            depth_array[inx, :, :, :] = depth\n",
    "        else:\n",
    "            (img0, img1, img2, depth, field_id) = d\n",
    "            img0_array[inx, :, :, :] = img0\n",
    "            img1_array[inx, :, :, :] = img1\n",
    "            img2_array[inx, :, :, :] = img2\n",
    "            depth_array[inx, :, :, :] = depth\n",
    "    if isTrain:\n",
    "        return img0_array, img1_array, img2_array, depth_array, y_array\n",
    "    return img0_array, img1_array, img2_array, depth_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.81 GiB for an array with shape (3396, 224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img0_array, img1_array, img2_array, depth_array, y_array \u001b[39m=\u001b[39m tensorToArray(data\u001b[39m=\u001b[39;49mdata_train, isTrain\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      2\u001b[0m img0_array_test, img1_array_test, img2_array_test, depth_array_test \u001b[39m=\u001b[39m tensorToArray(data\u001b[39m=\u001b[39mdata_test, isTrain\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [9], line 12\u001b[0m, in \u001b[0;36mtensorToArray\u001b[1;34m(data, isTrain)\u001b[0m\n\u001b[0;32m     10\u001b[0m img0_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(shape\u001b[39m=\u001b[39m(n_samples, img_shape[\u001b[39m0\u001b[39m], img_shape[\u001b[39m1\u001b[39m], img_shape[\u001b[39m2\u001b[39m]))\n\u001b[0;32m     11\u001b[0m img1_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(shape\u001b[39m=\u001b[39m(n_samples, img_shape[\u001b[39m0\u001b[39m], img_shape[\u001b[39m1\u001b[39m], img_shape[\u001b[39m2\u001b[39m]))\n\u001b[1;32m---> 12\u001b[0m img2_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(shape\u001b[39m=\u001b[39;49m(n_samples, img_shape[\u001b[39m0\u001b[39;49m], img_shape[\u001b[39m1\u001b[39;49m], img_shape[\u001b[39m2\u001b[39;49m]))\n\u001b[0;32m     13\u001b[0m depth_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(shape\u001b[39m=\u001b[39m(n_samples, depth_shape[\u001b[39m0\u001b[39m], depth_shape[\u001b[39m1\u001b[39m], depth_shape[\u001b[39m2\u001b[39m]))\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m inx, d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data):\n\u001b[0;32m     16\u001b[0m     \u001b[39m# print(inx)\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.81 GiB for an array with shape (3396, 224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "img0_array, img1_array, img2_array, depth_array, y_array = tensorToArray(data=data_train, isTrain=True)\n",
    "img0_array_test, img1_array_test, img2_array_test, depth_array_test = tensorToArray(data=data_test, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396, 224, 224, 3)\n",
      "(3396, 3, 224, 224)\n",
      "(3396, 12)\n"
     ]
    }
   ],
   "source": [
    "print(img0_array.shape)\n",
    "print(depth_array.shape)\n",
    "print(y_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The input shape should be (samples, width, height, 1)\n",
    "def depth_normalization(depth):\n",
    "    # normalized data = (data - Min number) / (Max number - Min number)\n",
    "    min_num = np.min(depth)\n",
    "    max_num = np.max(depth)\n",
    "    normalized_depth = (depth-min_num)/(max_num-min_num)\n",
    "    return normalized_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The input shape should be (samples, width, height, 1)\n",
    "def img_normalization(img):\n",
    "    # Original image data is from 0-255, and we want to scale data to 0-1. Thus, we can just divide original data by 255.\n",
    "    normalized_img = img/255.0\n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_depth = depth_normalization(depth=depth_array)\n",
    "normalized_img0 = img_normalization(img=img0_array)\n",
    "\n",
    "normalized_depth_test = depth_normalization(depth=depth_array_test)\n",
    "normalized_img0_test = img_normalization(img=img0_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def combine_image_depth(img, depth, whichImg=0):\n",
    "    new_img = np.empty(shape=(img.shape[0], img.shape[1], img.shape[2], img.shape[3]+1))\n",
    "\n",
    "    # First, try only use one image (img0), so use the first depth only.\n",
    "    depth0 = depth[:, whichImg, :, :]\n",
    "\n",
    "    for inx, _ in enumerate(img):\n",
    "        # 2D array (224, 224) to 3D array (224, 224, 1)\n",
    "        depth_4d = np.expand_dims(depth0[inx], 2)\n",
    "        # combine img and depth into one array\n",
    "        new_img[inx] = np.concatenate((img[inx], depth_4d), axis=2)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_img = combine_image_depth(img=normalized_img0, depth=normalized_depth)\n",
    "new_img_test = combine_image_depth(img=normalized_img0_test, depth=normalized_depth_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396, 224, 224, 4)\n",
      "(3396, 12)\n",
      "(849, 224, 224, 4)\n"
     ]
    }
   ],
   "source": [
    "print(new_img.shape)\n",
    "print(y_array.shape)\n",
    "print(new_img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Expected input data size for CNN is (Samples, Channels, Heights, Widths).\n",
    "# Thus, we have to reshape original data size (Samples, Heights, Widths, Channels) to the new size mentioned above.\n",
    "def reshape_data(data):\n",
    "    samples = data.shape[0]\n",
    "    channels = data.shape[3]\n",
    "    heights = data.shape[1]\n",
    "    widths = data.shape[2]\n",
    "    new_data = np.empty(shape=(samples, channels, heights, widths))\n",
    "\n",
    "    for i in range(channels):\n",
    "        new_data[:, i, :, :] = data[:, :, :, i]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ready_img = reshape_data(new_img)\n",
    "ready_img_test = reshape_data(new_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396, 4, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "print(ready_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(Tensor(ready_img),Tensor(y_array))\n",
    "train_dataloader = DataLoader(dataset=dataset_train, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_dict = [ready_img, y_array, ready_img_test]\n",
    "with open('lx_preprocessed_data.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(save_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('lx_preprocessed_data.pkl', 'rb') as f:\n",
    "    read_prep_data = pickle.load(f)\n",
    "tr_data, tr_y, te_data = read_prep_data[0], read_prep_data[1], read_prep_data[2]\n",
    "\n",
    "print(tr_data.shape)\n",
    "print(tr_y.shape)\n",
    "print(te_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "\n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "\n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "      identity = x.clone()\n",
    "\n",
    "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "      x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "      if self.i_downsample is not None:\n",
    "          identity = self.i_downsample(identity)\n",
    "      print(x.shape)\n",
    "      print(identity.shape)\n",
    "      x += identity\n",
    "      x = self.relu(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "\n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)\n",
    "\n",
    "def ResNet101(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,23,3], num_classes, channels)\n",
    "\n",
    "def ResNet152(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,8,36,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 12])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test = ResNet50(num_classes=12, channels=4)\n",
    "x = torch.Tensor(128, 4, 224, 224)\n",
    "y = model_test(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ResNet101(num_classes=12, channels=4)\n",
    "model = model.to(device)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "# optimizer = torch.optim.SGD(CNN.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(dataloader, model, loss_fn, optimizer, n_epoch):\n",
    "    for e in range(n_epoch):\n",
    "        model.train()\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {e+1}')\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "        for batch_inx, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            if batch_inx % 10 == 0:\n",
    "                print('Loss after mini-batch %5d: %.3f' % (batch_inx + 1, current_loss / 10))\n",
    "                current_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m(dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader, model\u001b[38;5;241m=\u001b[39mmodel, loss_fn\u001b[38;5;241m=\u001b[39mloss_function, optimizer\u001b[38;5;241m=\u001b[39moptimizer, n_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(dataloader=train_dataloader, model=model, loss_fn=loss_function, optimizer=optimizer, n_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_prediction = model(ready_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0YfvhbFyugnX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def test(dataloader, model, loss_fn):\n",
    "#   size = len(dataloader.dataset)\n",
    "#   num_batch = len(dataloader)\n",
    "#   model.eval()\n",
    "#   test_loss, correct = 0, 0\n",
    "#   with torch.no_grad():\n",
    "#     for x, y in dataloader:\n",
    "#       x, y = x.to(device), y.to(device)\n",
    "#       pred = model(x)\n",
    "#       test_loss += loss_fn(pred, y).item()\n",
    "#       correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "#   test_loss /= num_batch\n",
    "#   correct /= size\n",
    "#   print(f'test error \\n accuracy: {(100 * correct):>0.1f} %, avg loss: {test_loss:>8f} \\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08db28d5eb0c49dded8418f39112c5182545741fa4757240f7b057799e2856f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
