{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import CNN_model\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "from torch import Tensor\n",
    "from joblib import dump, load\n",
    "import submission\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = CNN_model.CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_step0 = cnn_model.main(loadname = 'lx_preprocessed_data0.joblib', pre_trained_model = None)\n",
    "model_step1 = cnn_model.main(loadname = 'lx_preprocessed_data1.joblib', pre_trained_model = model_step0)\n",
    "model_step2 = cnn_model.main(loadname = 'lx_preprocessed_data2.joblib', pre_trained_model = model_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.0213987797\n",
      "Loss after mini-batch    11: 0.5175946856\n",
      "Loss after mini-batch    21: 0.0057093226\n",
      "Loss after mini-batch    31: 0.0039582049\n",
      "Loss after mini-batch    41: 0.0020513223\n",
      "Loss after mini-batch    51: 0.0009687775\n",
      "Loss after mini-batch    61: 0.0007586151\n",
      "Loss after mini-batch    71: 0.0006673849\n",
      "Loss after mini-batch    81: 0.0008648684\n",
      "Loss after mini-batch    91: 0.0005479341\n",
      "Loss after mini-batch   101: 0.0004073409\n",
      "Loss after mini-batch   111: 0.0004540162\n",
      "Loss after mini-batch   121: 0.0004439252\n",
      "Loss after mini-batch   131: 0.0007001483\n",
      "Loss after mini-batch   141: 0.0005355409\n",
      "Loss after mini-batch   151: 0.0003775057\n",
      "Loss after mini-batch   161: 0.0004230013\n",
      "Loss after mini-batch   171: 0.0006982020\n",
      "Loss after mini-batch   181: 0.0006342489\n",
      "Loss after mini-batch   191: 0.0003930753\n",
      "Loss after mini-batch   201: 0.0003942552\n",
      "Loss after mini-batch   211: 0.0004869558\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.0000552852\n",
      "Loss after mini-batch    11: 0.0002987098\n",
      "Loss after mini-batch    21: 0.0003797892\n",
      "Loss after mini-batch    31: 0.0002963277\n",
      "Loss after mini-batch    41: 0.0002556729\n",
      "Loss after mini-batch    51: 0.0003034648\n",
      "Loss after mini-batch    61: 0.0002509175\n",
      "Loss after mini-batch    71: 0.0003079518\n",
      "Loss after mini-batch    81: 0.0005726387\n",
      "Loss after mini-batch    91: 0.0005462369\n",
      "Loss after mini-batch   101: 0.0005651693\n",
      "Loss after mini-batch   111: 0.0004002195\n",
      "Loss after mini-batch   121: 0.0004762774\n",
      "Loss after mini-batch   131: 0.0002784587\n",
      "Loss after mini-batch   141: 0.0003591733\n",
      "Loss after mini-batch   151: 0.0003052838\n",
      "Loss after mini-batch   161: 0.0003327945\n",
      "Loss after mini-batch   171: 0.0004939519\n",
      "Loss after mini-batch   181: 0.0004910739\n",
      "Loss after mini-batch   191: 0.0004467283\n",
      "Loss after mini-batch   201: 0.0004607883\n",
      "Loss after mini-batch   211: 0.0004482107\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.0000336862\n",
      "Loss after mini-batch    11: 0.0003025124\n",
      "Loss after mini-batch    21: 0.0002768509\n",
      "Loss after mini-batch    31: 0.0002682069\n",
      "Loss after mini-batch    41: 0.0003238980\n",
      "Loss after mini-batch    51: 0.0003460464\n",
      "Loss after mini-batch    61: 0.0005014032\n",
      "Loss after mini-batch    71: 0.0006379077\n",
      "Loss after mini-batch    81: 0.0006353346\n",
      "Loss after mini-batch    91: 0.0002906220\n",
      "Loss after mini-batch   101: 0.0003358420\n",
      "Loss after mini-batch   111: 0.0003051873\n",
      "Loss after mini-batch   121: 0.0002922249\n",
      "Loss after mini-batch   131: 0.0002568571\n",
      "Loss after mini-batch   141: 0.0002024565\n",
      "Loss after mini-batch   151: 0.0002542635\n",
      "Loss after mini-batch   161: 0.0003552860\n",
      "Loss after mini-batch   171: 0.0004206819\n",
      "Loss after mini-batch   181: 0.0002975031\n",
      "Loss after mini-batch   191: 0.0001938145\n",
      "Loss after mini-batch   201: 0.0002992759\n",
      "Loss after mini-batch   211: 0.0003648531\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.0000667864\n",
      "Loss after mini-batch    11: 0.0003885450\n",
      "Loss after mini-batch    21: 0.0003314050\n",
      "Loss after mini-batch    31: 0.0005300144\n",
      "Loss after mini-batch    41: 0.0006686603\n",
      "Loss after mini-batch    51: 0.0003050859\n",
      "Loss after mini-batch    61: 0.0004825533\n",
      "Loss after mini-batch    71: 0.0003090731\n",
      "Loss after mini-batch    81: 0.0003684899\n",
      "Loss after mini-batch    91: 0.0005204768\n",
      "Loss after mini-batch   101: 0.0003242823\n",
      "Loss after mini-batch   111: 0.0004195511\n",
      "Loss after mini-batch   121: 0.0004282192\n",
      "Loss after mini-batch   131: 0.0005044156\n",
      "Loss after mini-batch   141: 0.0002408948\n",
      "Loss after mini-batch   151: 0.0002526635\n",
      "Loss after mini-batch   161: 0.0002674485\n",
      "Loss after mini-batch   171: 0.0003816647\n",
      "Loss after mini-batch   181: 0.0003355507\n",
      "Loss after mini-batch   191: 0.0003245529\n",
      "Loss after mini-batch   201: 0.0004745420\n",
      "Loss after mini-batch   211: 0.0003787649\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.0001216267\n",
      "Loss after mini-batch    11: 0.0004412872\n",
      "Loss after mini-batch    21: 0.0004053028\n",
      "Loss after mini-batch    31: 0.0001744917\n",
      "Loss after mini-batch    41: 0.0002250645\n",
      "Loss after mini-batch    51: 0.0002743469\n",
      "Loss after mini-batch    61: 0.0004749396\n",
      "Loss after mini-batch    71: 0.0002898845\n",
      "Loss after mini-batch    81: 0.0003820385\n",
      "Loss after mini-batch    91: 0.0002804377\n",
      "Loss after mini-batch   101: 0.0002601791\n",
      "Loss after mini-batch   111: 0.0003111784\n",
      "Loss after mini-batch   121: 0.0003599882\n",
      "Loss after mini-batch   131: 0.0005999194\n",
      "Loss after mini-batch   141: 0.0003833828\n",
      "Loss after mini-batch   151: 0.0003341627\n",
      "Loss after mini-batch   161: 0.0007749575\n",
      "Loss after mini-batch   171: 0.0008712428\n",
      "Loss after mini-batch   181: 0.0010832862\n",
      "Loss after mini-batch   191: 0.0005173739\n",
      "Loss after mini-batch   201: 0.0003412847\n",
      "Loss after mini-batch   211: 0.0002835513\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.0000591733\n",
      "Loss after mini-batch    11: 0.0005376669\n",
      "Loss after mini-batch    21: 0.0005438003\n",
      "Loss after mini-batch    31: 0.0006206923\n",
      "Loss after mini-batch    41: 0.0004040020\n",
      "Loss after mini-batch    51: 0.0004194303\n",
      "Loss after mini-batch    61: 0.0002923162\n",
      "Loss after mini-batch    71: 0.0002985598\n",
      "Loss after mini-batch    81: 0.0003936592\n",
      "Loss after mini-batch    91: 0.0003867279\n",
      "Loss after mini-batch   101: 0.0003621116\n",
      "Loss after mini-batch   111: 0.0004074404\n",
      "Loss after mini-batch   121: 0.0003418919\n",
      "Loss after mini-batch   131: 0.0002769284\n",
      "Loss after mini-batch   141: 0.0002075330\n",
      "Loss after mini-batch   151: 0.0002353149\n",
      "Loss after mini-batch   161: 0.0001935315\n",
      "Loss after mini-batch   171: 0.0001432113\n",
      "Loss after mini-batch   181: 0.0001709581\n",
      "Loss after mini-batch   191: 0.0002665155\n",
      "Loss after mini-batch   201: 0.0004731155\n",
      "Loss after mini-batch   211: 0.0003104524\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.0000414499\n",
      "Loss after mini-batch    11: 0.0003048989\n",
      "Loss after mini-batch    21: 0.0002227425\n",
      "Loss after mini-batch    31: 0.0004228507\n",
      "Loss after mini-batch    41: 0.0003118202\n",
      "Loss after mini-batch    51: 0.0003098715\n",
      "Loss after mini-batch    61: 0.0002590964\n",
      "Loss after mini-batch    71: 0.0001831526\n",
      "Loss after mini-batch    81: 0.0002195946\n",
      "Loss after mini-batch    91: 0.0002795488\n",
      "Loss after mini-batch   101: 0.0001968180\n",
      "Loss after mini-batch   111: 0.0003015055\n",
      "Loss after mini-batch   121: 0.0001937801\n",
      "Loss after mini-batch   131: 0.0002018376\n",
      "Loss after mini-batch   141: 0.0002864839\n",
      "Loss after mini-batch   151: 0.0002323783\n",
      "Loss after mini-batch   161: 0.0002625107\n",
      "Loss after mini-batch   171: 0.0002047702\n",
      "Loss after mini-batch   181: 0.0001907091\n",
      "Loss after mini-batch   191: 0.0001620706\n",
      "Loss after mini-batch   201: 0.0002250187\n",
      "Loss after mini-batch   211: 0.0001764324\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.0000242129\n",
      "Loss after mini-batch    11: 0.0002474490\n",
      "Loss after mini-batch    21: 0.0003049169\n",
      "Loss after mini-batch    31: 0.0002307537\n",
      "Loss after mini-batch    41: 0.0002068715\n",
      "Loss after mini-batch    51: 0.0001757390\n",
      "Loss after mini-batch    61: 0.0001334399\n",
      "Loss after mini-batch    71: 0.0001279282\n",
      "Loss after mini-batch    81: 0.0001511174\n",
      "Loss after mini-batch    91: 0.0001619369\n",
      "Loss after mini-batch   101: 0.0002140101\n",
      "Loss after mini-batch   111: 0.0002128427\n",
      "Loss after mini-batch   121: 0.0002908805\n",
      "Loss after mini-batch   131: 0.0002320998\n",
      "Loss after mini-batch   141: 0.0002319587\n",
      "Loss after mini-batch   151: 0.0001519238\n",
      "Loss after mini-batch   161: 0.0001085235\n",
      "Loss after mini-batch   171: 0.0001532547\n",
      "Loss after mini-batch   181: 0.0002121650\n",
      "Loss after mini-batch   191: 0.0001879576\n",
      "Loss after mini-batch   201: 0.0001741509\n",
      "Loss after mini-batch   211: 0.0001252888\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.0000213367\n",
      "Loss after mini-batch    11: 0.0001911922\n",
      "Loss after mini-batch    21: 0.0001645316\n",
      "Loss after mini-batch    31: 0.0001265373\n",
      "Loss after mini-batch    41: 0.0001143808\n",
      "Loss after mini-batch    51: 0.0001907362\n",
      "Loss after mini-batch    61: 0.0002047650\n",
      "Loss after mini-batch    71: 0.0002268346\n",
      "Loss after mini-batch    81: 0.0001529111\n",
      "Loss after mini-batch    91: 0.0001616803\n",
      "Loss after mini-batch   101: 0.0002007863\n",
      "Loss after mini-batch   111: 0.0001131966\n",
      "Loss after mini-batch   121: 0.0001424940\n",
      "Loss after mini-batch   131: 0.0001069630\n",
      "Loss after mini-batch   141: 0.0000901390\n",
      "Loss after mini-batch   151: 0.0001155308\n",
      "Loss after mini-batch   161: 0.0001152396\n",
      "Loss after mini-batch   171: 0.0001027441\n",
      "Loss after mini-batch   181: 0.0000991235\n",
      "Loss after mini-batch   191: 0.0001768527\n",
      "Loss after mini-batch   201: 0.0001584601\n",
      "Loss after mini-batch   211: 0.0001282939\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.0000311931\n",
      "Loss after mini-batch    11: 0.0001519618\n",
      "Loss after mini-batch    21: 0.0000988276\n",
      "Loss after mini-batch    31: 0.0000961072\n",
      "Loss after mini-batch    41: 0.0001160664\n",
      "Loss after mini-batch    51: 0.0001301722\n",
      "Loss after mini-batch    61: 0.0001533557\n",
      "Loss after mini-batch    71: 0.0001205190\n",
      "Loss after mini-batch    81: 0.0001052285\n",
      "Loss after mini-batch    91: 0.0001292143\n",
      "Loss after mini-batch   101: 0.0001552454\n",
      "Loss after mini-batch   111: 0.0002139256\n",
      "Loss after mini-batch   121: 0.0001975301\n",
      "Loss after mini-batch   131: 0.0001708738\n",
      "Loss after mini-batch   141: 0.0002241378\n",
      "Loss after mini-batch   151: 0.0001431625\n",
      "Loss after mini-batch   161: 0.0000942441\n",
      "Loss after mini-batch   171: 0.0000958990\n",
      "Loss after mini-batch   181: 0.0001286707\n",
      "Loss after mini-batch   191: 0.0001216363\n",
      "Loss after mini-batch   201: 0.0001048094\n",
      "Loss after mini-batch   211: 0.0001259451\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.0000168492\n",
      "Loss after mini-batch    11: 0.0001219413\n",
      "Loss after mini-batch    21: 0.0001141369\n",
      "Loss after mini-batch    31: 0.0001291144\n",
      "Loss after mini-batch    41: 0.0001491439\n",
      "Loss after mini-batch    51: 0.0001126503\n",
      "Loss after mini-batch    61: 0.0000983172\n",
      "Loss after mini-batch    71: 0.0001085649\n",
      "Loss after mini-batch    81: 0.0001167055\n",
      "Loss after mini-batch    91: 0.0001683079\n",
      "Loss after mini-batch   101: 0.0001622203\n",
      "Loss after mini-batch   111: 0.0002455972\n",
      "Loss after mini-batch   121: 0.0002884769\n",
      "Loss after mini-batch   131: 0.0001687583\n",
      "Loss after mini-batch   141: 0.0001154779\n",
      "Loss after mini-batch   151: 0.0001269542\n",
      "Loss after mini-batch   161: 0.0001056932\n",
      "Loss after mini-batch   171: 0.0000781300\n",
      "Loss after mini-batch   181: 0.0000961249\n",
      "Loss after mini-batch   191: 0.0000763520\n",
      "Loss after mini-batch   201: 0.0000570723\n",
      "Loss after mini-batch   211: 0.0000590079\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.0000161842\n",
      "Loss after mini-batch    11: 0.0001123154\n",
      "Loss after mini-batch    21: 0.0001377322\n",
      "Loss after mini-batch    31: 0.0001245379\n",
      "Loss after mini-batch    41: 0.0001060359\n",
      "Loss after mini-batch    51: 0.0000813065\n",
      "Loss after mini-batch    61: 0.0001287969\n",
      "Loss after mini-batch    71: 0.0000964341\n",
      "Loss after mini-batch    81: 0.0001219101\n",
      "Loss after mini-batch    91: 0.0000818559\n",
      "Loss after mini-batch   101: 0.0001564998\n",
      "Loss after mini-batch   111: 0.0001803912\n",
      "Loss after mini-batch   121: 0.0001585419\n",
      "Loss after mini-batch   131: 0.0002526478\n",
      "Loss after mini-batch   141: 0.0002591105\n",
      "Loss after mini-batch   151: 0.0001908752\n",
      "Loss after mini-batch   161: 0.0001950730\n",
      "Loss after mini-batch   171: 0.0002680308\n",
      "Loss after mini-batch   181: 0.0002799394\n",
      "Loss after mini-batch   191: 0.0001964122\n",
      "Loss after mini-batch   201: 0.0001618323\n",
      "Loss after mini-batch   211: 0.0000780803\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.0000102523\n",
      "Loss after mini-batch    11: 0.0001465663\n",
      "Loss after mini-batch    21: 0.0001405276\n",
      "Loss after mini-batch    31: 0.0000941047\n",
      "Loss after mini-batch    41: 0.0000673576\n",
      "Loss after mini-batch    51: 0.0000629502\n",
      "Loss after mini-batch    61: 0.0000714139\n",
      "Loss after mini-batch    71: 0.0000941005\n",
      "Loss after mini-batch    81: 0.0001068531\n",
      "Loss after mini-batch    91: 0.0000874859\n",
      "Loss after mini-batch   101: 0.0000914320\n",
      "Loss after mini-batch   111: 0.0000727745\n",
      "Loss after mini-batch   121: 0.0000961767\n",
      "Loss after mini-batch   131: 0.0000761680\n",
      "Loss after mini-batch   141: 0.0000880330\n",
      "Loss after mini-batch   151: 0.0000619074\n",
      "Loss after mini-batch   161: 0.0000629542\n",
      "Loss after mini-batch   171: 0.0000849613\n",
      "Loss after mini-batch   181: 0.0001098409\n",
      "Loss after mini-batch   191: 0.0001240569\n",
      "Loss after mini-batch   201: 0.0001230459\n",
      "Loss after mini-batch   211: 0.0001206809\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.0000331250\n",
      "Loss after mini-batch    11: 0.0001763258\n",
      "Loss after mini-batch    21: 0.0001075290\n",
      "Loss after mini-batch    31: 0.0001309452\n",
      "Loss after mini-batch    41: 0.0001112569\n",
      "Loss after mini-batch    51: 0.0001217072\n",
      "Loss after mini-batch    61: 0.0001114703\n",
      "Loss after mini-batch    71: 0.0000806088\n",
      "Loss after mini-batch    81: 0.0001083327\n",
      "Loss after mini-batch    91: 0.0000916803\n",
      "Loss after mini-batch   101: 0.0000695930\n",
      "Loss after mini-batch   111: 0.0001025155\n",
      "Loss after mini-batch   121: 0.0001033579\n",
      "Loss after mini-batch   131: 0.0000810070\n",
      "Loss after mini-batch   141: 0.0000559154\n",
      "Loss after mini-batch   151: 0.0000585226\n",
      "Loss after mini-batch   161: 0.0000701610\n",
      "Loss after mini-batch   171: 0.0000846011\n",
      "Loss after mini-batch   181: 0.0000983024\n",
      "Loss after mini-batch   191: 0.0000909812\n",
      "Loss after mini-batch   201: 0.0000937302\n",
      "Loss after mini-batch   211: 0.0000731358\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.0000100700\n",
      "Loss after mini-batch    11: 0.0000833966\n",
      "Loss after mini-batch    21: 0.0000815187\n",
      "Loss after mini-batch    31: 0.0000621117\n",
      "Loss after mini-batch    41: 0.0000452790\n",
      "Loss after mini-batch    51: 0.0000519228\n",
      "Loss after mini-batch    61: 0.0000383336\n",
      "Loss after mini-batch    71: 0.0000416000\n",
      "Loss after mini-batch    81: 0.0000600434\n",
      "Loss after mini-batch    91: 0.0000639882\n",
      "Loss after mini-batch   101: 0.0000769919\n",
      "Loss after mini-batch   111: 0.0001001048\n",
      "Loss after mini-batch   121: 0.0000715952\n",
      "Loss after mini-batch   131: 0.0000664482\n",
      "Loss after mini-batch   141: 0.0000904891\n",
      "Loss after mini-batch   151: 0.0000971012\n",
      "Loss after mini-batch   161: 0.0000776864\n",
      "Loss after mini-batch   171: 0.0000831892\n",
      "Loss after mini-batch   181: 0.0000683694\n",
      "Loss after mini-batch   191: 0.0000643969\n",
      "Loss after mini-batch   201: 0.0000591913\n",
      "Loss after mini-batch   211: 0.0000658431\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.0000090904\n",
      "Loss after mini-batch    11: 0.0000710995\n",
      "Loss after mini-batch    21: 0.0000778963\n",
      "Loss after mini-batch    31: 0.0000756315\n",
      "Loss after mini-batch    41: 0.0000693840\n",
      "Loss after mini-batch    51: 0.0000567109\n",
      "Loss after mini-batch    61: 0.0000576266\n",
      "Loss after mini-batch    71: 0.0000492410\n",
      "Loss after mini-batch    81: 0.0000474238\n",
      "Loss after mini-batch    91: 0.0000623559\n",
      "Loss after mini-batch   101: 0.0000583869\n",
      "Loss after mini-batch   111: 0.0000817546\n",
      "Loss after mini-batch   121: 0.0000971182\n",
      "Loss after mini-batch   131: 0.0000674524\n",
      "Loss after mini-batch   141: 0.0000896198\n",
      "Loss after mini-batch   151: 0.0000567922\n",
      "Loss after mini-batch   161: 0.0000600271\n",
      "Loss after mini-batch   171: 0.0000676434\n",
      "Loss after mini-batch   181: 0.0000659958\n",
      "Loss after mini-batch   191: 0.0000885834\n",
      "Loss after mini-batch   201: 0.0000863250\n",
      "Loss after mini-batch   211: 0.0000620681\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.0000049904\n",
      "Loss after mini-batch    11: 0.0000507222\n",
      "Loss after mini-batch    21: 0.0000560566\n",
      "Loss after mini-batch    31: 0.0000694116\n",
      "Loss after mini-batch    41: 0.0000689678\n",
      "Loss after mini-batch    51: 0.0000668189\n",
      "Loss after mini-batch    61: 0.0000500757\n",
      "Loss after mini-batch    71: 0.0000556935\n",
      "Loss after mini-batch    81: 0.0000661858\n",
      "Loss after mini-batch    91: 0.0000596040\n",
      "Loss after mini-batch   101: 0.0000666500\n",
      "Loss after mini-batch   111: 0.0000482277\n",
      "Loss after mini-batch   121: 0.0000492515\n",
      "Loss after mini-batch   131: 0.0000550428\n",
      "Loss after mini-batch   141: 0.0000526715\n",
      "Loss after mini-batch   151: 0.0000610491\n",
      "Loss after mini-batch   161: 0.0000421562\n",
      "Loss after mini-batch   171: 0.0000393958\n",
      "Loss after mini-batch   181: 0.0000396783\n",
      "Loss after mini-batch   191: 0.0000636969\n",
      "Loss after mini-batch   201: 0.0000869365\n",
      "Loss after mini-batch   211: 0.0000823170\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.0000082170\n",
      "Loss after mini-batch    11: 0.0001084225\n",
      "Loss after mini-batch    21: 0.0000979262\n",
      "Loss after mini-batch    31: 0.0000655851\n",
      "Loss after mini-batch    41: 0.0000714769\n",
      "Loss after mini-batch    51: 0.0000940376\n",
      "Loss after mini-batch    61: 0.0000963974\n",
      "Loss after mini-batch    71: 0.0000587822\n",
      "Loss after mini-batch    81: 0.0000503412\n",
      "Loss after mini-batch    91: 0.0000558079\n",
      "Loss after mini-batch   101: 0.0000472159\n",
      "Loss after mini-batch   111: 0.0000429719\n",
      "Loss after mini-batch   121: 0.0000419167\n",
      "Loss after mini-batch   131: 0.0000559280\n",
      "Loss after mini-batch   141: 0.0000633504\n",
      "Loss after mini-batch   151: 0.0000511696\n",
      "Loss after mini-batch   161: 0.0000394802\n",
      "Loss after mini-batch   171: 0.0000337184\n",
      "Loss after mini-batch   181: 0.0000497748\n",
      "Loss after mini-batch   191: 0.0000771149\n",
      "Loss after mini-batch   201: 0.0000553230\n",
      "Loss after mini-batch   211: 0.0000561708\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.0000075368\n",
      "Loss after mini-batch    11: 0.0000595261\n",
      "Loss after mini-batch    21: 0.0000802410\n",
      "Loss after mini-batch    31: 0.0000889748\n",
      "Loss after mini-batch    41: 0.0001052216\n",
      "Loss after mini-batch    51: 0.0000720321\n",
      "Loss after mini-batch    61: 0.0000537796\n",
      "Loss after mini-batch    71: 0.0000627071\n",
      "Loss after mini-batch    81: 0.0000520836\n",
      "Loss after mini-batch    91: 0.0000367128\n",
      "Loss after mini-batch   101: 0.0000445439\n",
      "Loss after mini-batch   111: 0.0000543907\n",
      "Loss after mini-batch   121: 0.0000790563\n",
      "Loss after mini-batch   131: 0.0000724747\n",
      "Loss after mini-batch   141: 0.0000689220\n",
      "Loss after mini-batch   151: 0.0000811253\n",
      "Loss after mini-batch   161: 0.0000751481\n",
      "Loss after mini-batch   171: 0.0000605161\n",
      "Loss after mini-batch   181: 0.0000611034\n",
      "Loss after mini-batch   191: 0.0000425642\n",
      "Loss after mini-batch   201: 0.0000371489\n",
      "Loss after mini-batch   211: 0.0000386890\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.0000051311\n",
      "Loss after mini-batch    11: 0.0000490384\n",
      "Loss after mini-batch    21: 0.0000470844\n",
      "Loss after mini-batch    31: 0.0000354031\n",
      "Loss after mini-batch    41: 0.0000446953\n",
      "Loss after mini-batch    51: 0.0000390314\n",
      "Loss after mini-batch    61: 0.0000415200\n",
      "Loss after mini-batch    71: 0.0000679974\n",
      "Loss after mini-batch    81: 0.0000413554\n",
      "Loss after mini-batch    91: 0.0000477094\n",
      "Loss after mini-batch   101: 0.0000606603\n",
      "Loss after mini-batch   111: 0.0000504548\n",
      "Loss after mini-batch   121: 0.0000498889\n",
      "Loss after mini-batch   131: 0.0000719696\n",
      "Loss after mini-batch   141: 0.0000544689\n",
      "Loss after mini-batch   151: 0.0000504578\n",
      "Loss after mini-batch   161: 0.0000906616\n",
      "Loss after mini-batch   171: 0.0000515007\n",
      "Loss after mini-batch   181: 0.0000523473\n",
      "Loss after mini-batch   191: 0.0000547360\n",
      "Loss after mini-batch   201: 0.0000486140\n",
      "Loss after mini-batch   211: 0.0000353980\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.0000061821\n",
      "Loss after mini-batch    11: 0.0000528349\n",
      "Loss after mini-batch    21: 0.0000456661\n",
      "Loss after mini-batch    31: 0.0000469294\n",
      "Loss after mini-batch    41: 0.0000471464\n",
      "Loss after mini-batch    51: 0.0000422876\n",
      "Loss after mini-batch    61: 0.0000429840\n",
      "Loss after mini-batch    71: 0.0000428747\n",
      "Loss after mini-batch    81: 0.0000517544\n",
      "Loss after mini-batch    91: 0.0000455161\n",
      "Loss after mini-batch   101: 0.0000506660\n",
      "Loss after mini-batch   111: 0.0000541271\n",
      "Loss after mini-batch   121: 0.0000380698\n",
      "Loss after mini-batch   131: 0.0000346895\n",
      "Loss after mini-batch   141: 0.0000344223\n",
      "Loss after mini-batch   151: 0.0000406862\n",
      "Loss after mini-batch   161: 0.0000504770\n",
      "Loss after mini-batch   171: 0.0000690977\n",
      "Loss after mini-batch   181: 0.0000493617\n",
      "Loss after mini-batch   191: 0.0000687377\n",
      "Loss after mini-batch   201: 0.0000568983\n",
      "Loss after mini-batch   211: 0.0000625417\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.0000224332\n",
      "Loss after mini-batch    11: 0.0000958218\n",
      "Loss after mini-batch    21: 0.0000595518\n",
      "Loss after mini-batch    31: 0.0000532685\n",
      "Loss after mini-batch    41: 0.0000512542\n",
      "Loss after mini-batch    51: 0.0000370820\n",
      "Loss after mini-batch    61: 0.0000359955\n",
      "Loss after mini-batch    71: 0.0000398150\n",
      "Loss after mini-batch    81: 0.0000488922\n",
      "Loss after mini-batch    91: 0.0000494390\n",
      "Loss after mini-batch   101: 0.0000592571\n",
      "Loss after mini-batch   111: 0.0000582101\n",
      "Loss after mini-batch   121: 0.0000552935\n",
      "Loss after mini-batch   131: 0.0000761308\n",
      "Loss after mini-batch   141: 0.0000575972\n",
      "Loss after mini-batch   151: 0.0000396192\n",
      "Loss after mini-batch   161: 0.0000316991\n",
      "Loss after mini-batch   171: 0.0000427661\n",
      "Loss after mini-batch   181: 0.0000515322\n",
      "Loss after mini-batch   191: 0.0000368172\n",
      "Loss after mini-batch   201: 0.0000433285\n",
      "Loss after mini-batch   211: 0.0000370408\n"
     ]
    }
   ],
   "source": [
    "cnn_model = cnn_model.main(loadname = 'lx_preprocessed_data.joblib', pre_trained_model = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = cnn_model.main(loadname = 'lx_preprocessed_data1.joblib', pre_trained_model = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = cnn_model.main(loadname = 'lx_preprocessed_data2.joblib', pre_trained_model = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(cnn_model) # Export to TorchScript\n",
    "model_scripted.save('res50_pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = cnn_model.pred(model_name='res50_pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dp = CNN_model.Data_Preprocessing()\n",
    "data_train = CNN_model.load_images(path='./lazydata/', isTrain = True)\n",
    "data_test = CNN_model.load_images(path='./lazydata/', isTrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img0_array_test, img1_array_test, img2_array_test, depth_array_test, field_id_array = dp.tensorToArray(data=data_test, isTrain=False)\n",
    "img0_array_train, img1_array_train, img2_array_train, depth_array_train, y_array = dp.tensorToArray(data=data_train, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "normalized_depth_test = dp.depth_normalization(depth=depth_array_test)\n",
    "\n",
    "normalized_img0_test = dp.img_normalization(img=img0_array_test)\n",
    "new_img_test = dp.combine_image_depth(img=normalized_img0_test, depth=normalized_depth_test)\n",
    "ready_img_test = dp.reshape_data(new_img_test)\n",
    "\n",
    "normalized_img1_test = dp.img_normalization(img=img1_array_test)\n",
    "new_img1_test = dp.combine_image_depth(img=normalized_img1_test, depth=normalized_depth_test)\n",
    "ready_img1_test = dp.reshape_data(new_img1_test)\n",
    "\n",
    "normalized_img2_test = dp.img_normalization(img=img2_array_test)\n",
    "new_img2_test = dp.combine_image_depth(img=normalized_img2_test, depth=normalized_depth_test)\n",
    "ready_img2_test = dp.reshape_data(new_img2_test)\n",
    "\n",
    "# train\n",
    "normalized_depth_train = dp.depth_normalization(depth=depth_array_train)\n",
    "\n",
    "normalized_img0_train = dp.img_normalization(img=img0_array_train)\n",
    "new_img_train = dp.combine_image_depth(img=normalized_img0_train, depth=normalized_depth_train, whichImg = 0)\n",
    "ready_img_train = dp.reshape_data(new_img_train)\n",
    "\n",
    "normalized_img1_train = dp.img_normalization(img=img1_array_train)\n",
    "new_img_train1 = dp.combine_image_depth(img=normalized_img1_train, depth=normalized_depth_train, whichImg = 1)\n",
    "ready_img_train1 = dp.reshape_data(new_img_train1)\n",
    "\n",
    "normalized_img2_train = dp.img_normalization(img=img2_array_train)\n",
    "new_img_train2 = dp.combine_image_depth(img=normalized_img2_train, depth=normalized_depth_train, whichImg = 2)\n",
    "ready_img_train2 = dp.reshape_data(new_img_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "testX = [ready_img_test, field_id_array]\n",
    "testX_img1 = [ready_img1_test, field_id_array]\n",
    "testX_img2 = [ready_img2_test, field_id_array]\n",
    "\n",
    "# train\n",
    "train_img0 = [ready_img_train, y_array]\n",
    "train_img1 = [ready_img_train1, y_array]\n",
    "train_img2 = [ready_img_train2, y_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "dump(testX, 'preprocessed_testX.joblib')\n",
    "dump(testX_img1, 'preprocessed_testX_img1.joblib')\n",
    "dump(testX_img2, 'preprocessed_testX_img2.joblib')\n",
    "\n",
    "# train\n",
    "dump(train_img0, 'lx_preprocessed_data0.joblib')\n",
    "dump(train_img1, 'lx_preprocessed_data1.joblib')\n",
    "dump(train_img2, 'lx_preprocessed_data2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sub = submission.Submission()\n",
    "df = sub.submit(filename = 'preprocessed_testX.joblib', modelname = 'res50_pretrained_model.pt')\n",
    "df = sub.submit(filename = 'preprocessed_testX_img1.joblib', modelname = 'res50_pretrained_model_img1.pt')\n",
    "df = sub.submit(filename = 'preprocessed_testX_img2.joblib', modelname = 'res50_pretrained_model_img2.pt')\n",
    "\n",
    "df = sub.submit(filename = 'preprocessed_testX.joblib', modelname = 'res50_pretrained_model_combine.pt')\n",
    "df = sub.submit(filename = 'preprocessed_testX_img1.joblib', modelname = 'res50_pretrained_model_combine.pt')\n",
    "df = sub.submit(filename = 'preprocessed_testX_img2.joblib', modelname = 'res50_pretrained_model_combine.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "08db28d5eb0c49dded8418f39112c5182545741fa4757240f7b057799e2856f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
