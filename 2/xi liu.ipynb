{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import CNN_model\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "from torch import Tensor\n",
    "from joblib import dump, load\n",
    "import submission\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = CNN_model.CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.035\n",
      "Loss after mini-batch    11: 0.441\n",
      "Loss after mini-batch    21: 0.006\n",
      "Loss after mini-batch    31: 0.005\n",
      "Loss after mini-batch    41: 0.002\n",
      "Loss after mini-batch    51: 0.004\n",
      "Loss after mini-batch    61: 0.003\n",
      "Loss after mini-batch    71: 0.002\n",
      "Loss after mini-batch    81: 0.001\n",
      "Loss after mini-batch    91: 0.001\n",
      "Loss after mini-batch   101: 0.001\n",
      "Loss after mini-batch   111: 0.001\n",
      "Loss after mini-batch   121: 0.001\n",
      "Loss after mini-batch   131: 0.001\n",
      "Loss after mini-batch   141: 0.001\n",
      "Loss after mini-batch   151: 0.001\n",
      "Loss after mini-batch   161: 0.001\n",
      "Loss after mini-batch   171: 0.001\n",
      "Loss after mini-batch   181: 0.001\n",
      "Loss after mini-batch   191: 0.001\n",
      "Loss after mini-batch   201: 0.001\n",
      "Loss after mini-batch   211: 0.001\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    31: 0.001\n",
      "Loss after mini-batch    41: 0.001\n",
      "Loss after mini-batch    51: 0.001\n",
      "Loss after mini-batch    61: 0.001\n",
      "Loss after mini-batch    71: 0.001\n",
      "Loss after mini-batch    81: 0.001\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.001\n",
      "Loss after mini-batch   111: 0.001\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.001\n",
      "Loss after mini-batch   141: 0.001\n",
      "Loss after mini-batch   151: 0.001\n",
      "Loss after mini-batch   161: 0.001\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.001\n",
      "Loss after mini-batch   201: 0.001\n",
      "Loss after mini-batch   211: 0.001\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    31: 0.001\n",
      "Loss after mini-batch    41: 0.001\n",
      "Loss after mini-batch    51: 0.001\n",
      "Loss after mini-batch    61: 0.001\n",
      "Loss after mini-batch    71: 0.001\n",
      "Loss after mini-batch    81: 0.001\n",
      "Loss after mini-batch    91: 0.001\n",
      "Loss after mini-batch   101: 0.002\n",
      "Loss after mini-batch   111: 0.001\n",
      "Loss after mini-batch   121: 0.001\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.001\n",
      "Loss after mini-batch    61: 0.001\n",
      "Loss after mini-batch    71: 0.001\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.001\n",
      "Loss after mini-batch   101: 0.001\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.001\n",
      "Loss after mini-batch   161: 0.001\n",
      "Loss after mini-batch   171: 0.001\n",
      "Loss after mini-batch   181: 0.001\n",
      "Loss after mini-batch   191: 0.002\n",
      "Loss after mini-batch   201: 0.001\n",
      "Loss after mini-batch   211: 0.001\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    31: 0.001\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.001\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.001\n",
      "Loss after mini-batch   111: 0.001\n",
      "Loss after mini-batch   121: 0.001\n",
      "Loss after mini-batch   131: 0.001\n",
      "Loss after mini-batch   141: 0.001\n",
      "Loss after mini-batch   151: 0.001\n",
      "Loss after mini-batch   161: 0.001\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.001\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.001\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.001\n",
      "Loss after mini-batch   181: 0.001\n",
      "Loss after mini-batch   191: 0.001\n",
      "Loss after mini-batch   201: 0.001\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.001\n",
      "Loss after mini-batch   121: 0.001\n",
      "Loss after mini-batch   131: 0.001\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.001\n",
      "Loss after mini-batch   111: 0.001\n",
      "Loss after mini-batch   121: 0.001\n",
      "Loss after mini-batch   131: 0.001\n",
      "Loss after mini-batch   141: 0.001\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    31: 0.000\n",
      "Loss after mini-batch    41: 0.000\n",
      "Loss after mini-batch    51: 0.000\n",
      "Loss after mini-batch    61: 0.000\n",
      "Loss after mini-batch    71: 0.000\n",
      "Loss after mini-batch    81: 0.000\n",
      "Loss after mini-batch    91: 0.000\n",
      "Loss after mini-batch   101: 0.000\n",
      "Loss after mini-batch   111: 0.000\n",
      "Loss after mini-batch   121: 0.000\n",
      "Loss after mini-batch   131: 0.000\n",
      "Loss after mini-batch   141: 0.000\n",
      "Loss after mini-batch   151: 0.000\n",
      "Loss after mini-batch   161: 0.000\n",
      "Loss after mini-batch   171: 0.000\n",
      "Loss after mini-batch   181: 0.000\n",
      "Loss after mini-batch   191: 0.000\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.000\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save('res50_pretrained_model.pt') # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.08 GiB for an array with shape (681590784,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[39m=\u001b[39m cnn_model\u001b[39m.\u001b[39;49mpred(model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mres50_pretrained_model.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\xi133\\Desktop\\book\\2022 fall\\machine learning\\hw\\final\\CNN_model.py:296\u001b[0m, in \u001b[0;36mCNN.pred\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    293\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(model_name)\n\u001b[0;32m    294\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 296\u001b[0m read_prep_data \u001b[39m=\u001b[39m load(\u001b[39m'\u001b[39;49m\u001b[39mlx_preprocessed_data.joblib\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    297\u001b[0m tr_data, tr_y, te_data \u001b[39m=\u001b[39m read_prep_data[\u001b[39m0\u001b[39m], read_prep_data[\u001b[39m1\u001b[39m], read_prep_data[\u001b[39m2\u001b[39m]\n\u001b[0;32m    299\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(te_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m12\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\xi133\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\xi133\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xi133\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\xi133\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:415\u001b[0m, in \u001b[0;36mNumpyUnpickler.load_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(array_wrapper, NDArrayWrapper):\n\u001b[0;32m    414\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompat_mode \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack\u001b[39m.\u001b[39mappend(array_wrapper\u001b[39m.\u001b[39;49mread(\u001b[39mself\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\xi133\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:252\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    250\u001b[0m     array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_mmap(unpickler)\n\u001b[0;32m    251\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m     array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(unpickler)\n\u001b[0;32m    254\u001b[0m \u001b[39m# Manage array subclass case\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mhasattr\u001b[39m(array, \u001b[39m'\u001b[39m\u001b[39m__array_prepare__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubclass \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (unpickler\u001b[39m.\u001b[39mnp\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m    257\u001b[0m                           unpickler\u001b[39m.\u001b[39mnp\u001b[39m.\u001b[39mmemmap)):\n\u001b[0;32m    258\u001b[0m     \u001b[39m# We need to reconstruct another subclass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xi133\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:173\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read_array\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39m# crc32 module fails on reads greater than 2 ** 32 bytes,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39m# of the read. In non-chunked case count < max_read_count, so\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m# only one read is performed.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m max_read_count \u001b[39m=\u001b[39m BUFFER_SIZE \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mmin\u001b[39m(BUFFER_SIZE,\n\u001b[0;32m    171\u001b[0m                                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mitemsize)\n\u001b[1;32m--> 173\u001b[0m array \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mnp\u001b[39m.\u001b[39;49mempty(count, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[0;32m    174\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, count, max_read_count):\n\u001b[0;32m    175\u001b[0m     read_count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_read_count, count \u001b[39m-\u001b[39m i)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.08 GiB for an array with shape (681590784,) and data type float64"
     ]
    }
   ],
   "source": [
    "# predictions = cnn_model.pred(model_name='res50_pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dp = CNN_model.Data_Preprocessing()\n",
    "# \"\"\"data_test = CNN_model.load_images(path='\\\\lazydata\\\\', isTrain = False)\"\"\"\n",
    "# data_test = CNN_model.load_images(path='./lazydata/', isTrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# img0_array_test, img1_array_test, img2_array_test, depth_array_test, field_id_array = dp.tensorToArray(data=data_test, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# normalized_depth_test = dp.depth_normalization(depth=depth_array_test)\n",
    "# normalized_img0_test = dp.img_normalization(img=img0_array_test)\n",
    "# new_img_test = dp.combine_image_depth(img=normalized_img0_test, depth=normalized_depth_test)\n",
    "# ready_img_test = dp.reshape_data(new_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# testX = [ready_img_test, field_id_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessed_testX.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump(testX, 'preprocessed_testX.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "finished load data\n",
      "finished prep test data\n",
      "finished load model\n",
      "Batch Index: 0\n",
      "Batch Index: 5\n",
      "Batch Index: 10\n",
      "Batch Index: 15\n",
      "Batch Index: 20\n",
      "Batch Index: 25\n",
      "Batch Index: 30\n",
      "Batch Index: 35\n",
      "Batch Index: 40\n",
      "Batch Index: 45\n",
      "Batch Index: 50\n",
      "Batch Index: 55\n",
      "Batch Index: 60\n",
      "Batch Index: 65\n",
      "Batch Index: 70\n",
      "Batch Index: 75\n",
      "Batch Index: 80\n",
      "Batch Index: 85\n",
      "Batch Index: 90\n",
      "Batch Index: 95\n",
      "Batch Index: 100\n",
      "Batch Index: 105\n",
      "finished predict\n",
      "Written to csv file submission.csv\n",
      "all finished\n"
     ]
    }
   ],
   "source": [
    "sub = submission.Submission()\n",
    "df = sub.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  FINGER_POS_1  FINGER_POS_2  FINGER_POS_3  FINGER_POS_4  \\\n",
      "0     146      0.035178      0.058471      0.124443      0.040848   \n",
      "1    1474      0.017532      0.059732      0.131612      0.024966   \n",
      "2     213      0.048420      0.057119      0.121578      0.085025   \n",
      "3    2831      0.063600      0.055244      0.112091      0.082448   \n",
      "4      26      0.032520      0.057880      0.129357      0.068256   \n",
      "..    ...           ...           ...           ...           ...   \n",
      "844    27      0.029213      0.057656      0.130070      0.063310   \n",
      "845  3226      0.045965      0.057245      0.123477      0.076885   \n",
      "846   833      0.064597      0.052860      0.105041      0.077688   \n",
      "847  3812      0.062399      0.051912      0.099502      0.062536   \n",
      "848   601      0.021078      0.058322      0.129868      0.047445   \n",
      "\n",
      "     FINGER_POS_5  FINGER_POS_6  FINGER_POS_7  FINGER_POS_8  FINGER_POS_9  \\\n",
      "0       -0.001806      0.119643      0.042544     -0.050594      0.105154   \n",
      "1       -0.001379      0.130654      0.006809     -0.054657      0.123658   \n",
      "2       -0.000708      0.057246      0.051811     -0.050294      0.063641   \n",
      "3       -0.001660      0.100535      0.074539     -0.040231      0.020142   \n",
      "4       -0.002623      0.097031      0.043312     -0.038532      0.020758   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "844     -0.001954      0.109302      0.044522     -0.037148      0.012389   \n",
      "845     -0.003702      0.095392      0.047787     -0.036059      0.023372   \n",
      "846     -0.001151      0.072842      0.085574     -0.042844      0.042562   \n",
      "847     -0.002825      0.081364      0.046812     -0.044965      0.059999   \n",
      "848      0.001480      0.122953      0.064808     -0.038922      0.023430   \n",
      "\n",
      "     FINGER_POS_10  FINGER_POS_11  FINGER_POS_12  \n",
      "0         0.052605       0.013275      -0.053101  \n",
      "1         0.048318       0.034013      -0.057565  \n",
      "2         0.054847       0.027114      -0.040778  \n",
      "3         0.066215       0.058179      -0.034855  \n",
      "4         0.055980       0.045002      -0.048692  \n",
      "..             ...            ...            ...  \n",
      "844       0.058400       0.039605      -0.055019  \n",
      "845       0.062692       0.013463      -0.069056  \n",
      "846       0.042639       0.070660      -0.021450  \n",
      "847       0.049835       0.026517      -0.067499  \n",
      "848       0.061837       0.027789      -0.049069  \n",
      "\n",
      "[849 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "08db28d5eb0c49dded8418f39112c5182545741fa4757240f7b057799e2856f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
